# Neural-Network
### cousera course 
neural network and deep learning by Andrew NG [-->](https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome)


## Activation Function
   #### Sigmoid 
           1/1+e^(-Z)
   #### tanh
           e^(z)-e^(-z)/e^(-z)+e^(z)
           
           
           
   #### softmax [-->](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1) 
   
   
   #### relu 
   max(0,Z)
   
   
 ## Regularization 
 
     L2 Regularization 
     
     Dropout
   
   
   Hand Written Digit recognition using CNN[-->](https://github.com/Ganeshpy3/Neural-Network/tree/main/kaggle%20competition)
   

